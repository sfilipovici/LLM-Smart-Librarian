# ğŸ“š LLM Smart Librarian

Un proiect pentru gestionarea È™i interacÈ›iunea cu documente folosind **Retrieval-Augmented Generation (RAG)** È™i interfeÈ›e de tip **chat** (CLI & UI).  
Scopul proiectului este sÄƒ permitÄƒ cÄƒutarea, rezumarea È™i monitorizarea rÄƒspunsurilor folosind modele LLM.

---

## ğŸš€ FuncÈ›ionalitÄƒÈ›i
- **Chat UI È™i CLI** pentru interacÈ›iune naturalÄƒ cu utilizatorul (`app/chat_ui.py`, `app/chat_cli.py`).
- **RAG Pipeline**:
  - *Ingestion* de documente (`rag/ingest.py`).
  - *Retriever* pentru cÄƒutare contextualÄƒ (`rag/retriever.py`).
- **Unelte de sumarizare** (`tools/summaries_tool.py`).
- **Monitorizare rÄƒspunsuri LLM** (`response_monitor.py`).
- **Extensibilitate**: suport pentru integrarea de noi unelte È™i surse de date.

---

## ğŸ“¦ Instalare

### 1. CloneazÄƒ repository-ul
```bash
git clone git@github.com:sfilipovici/LLM-Smart-Librarian.git
cd LLM-Smart-Librarian
```

### 2. CreeazÄƒ un mediu virtual
```bash
python3 -m venv venv
source venv/bin/activate
```

### 3. InstaleazÄƒ dependenÈ›ele
```bash
pip install -r requirements.txt
```

## ğŸ”‘ Configurare

CreeazÄƒ un fiÈ™ier .env pe baza template-ului:
```bash
cp .env.example .env
```

CompleteazÄƒ valorile necesare (de ex. OPENAI_API_KEY).

âš ï¸ NotÄƒ: Nu include niciodatÄƒ .env Ã®n repo! Este deja listat Ã®n .gitignore.

## â–¶ï¸ Utilizare
### 1. Ingestion documente
```bash
python rag/ingest.py
```

### Chat CLI
```bash
python app/chat_cli.py
```

### Chat Web UI
```bash
python app/chat_ui.py
```



## ğŸ“‚ Structura proiectului

```bash
LLM-Smart-Librarian/
â”‚â”€â”€ app/                 # InterfaÈ›Äƒ utilizator (UI + CLI)
â”‚â”€â”€ rag/                 # Ingestion È™i retrieval documente
â”‚â”€â”€ tools/               # Unelte suplimentare (summaries, etc.)
â”‚â”€â”€ response_monitor.py  # Monitorizare rÄƒspunsuri LLM
â”‚â”€â”€ requirements.txt     # DependenÈ›e Python
â”‚â”€â”€ .env.example         # Template pentru variabile de mediu
â”‚â”€â”€ .gitignore           # IgnorÄƒ fiÈ™iere sensibile / cache
```
